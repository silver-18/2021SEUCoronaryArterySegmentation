损失函数是深度学习中非常重要的一部分，是模型优化的关键。设计合适的损失函数可以提升网络的训练效率、提高图像分割的精确度。

- 加入重叠度量函数作为加权正则项
- 考生和考官网络使用不同的损失函数
- 有标签和无标签数据使用不同的损失函数
- 将一些传统的算法（？）加入卷积神经网络中
- 目的导向（直接降低Dice Loss？）



损失函数设计的准则？

#### **(综述)Deep Semantic Segmentation of Natural and Medical Images：A Review**

交叉熵、加权交叉熵、Focal Loss、Dice Loss...

图像分割（尤其是医学图像）中的一个重要问题是要克服类别不平衡问题。对于此类不平衡问题，基于重叠度量的方法在克服不平衡方面表现良好。

在分割大小对象时，基于重叠的函数会高度波动，这会导致优化不稳定。使用交叉熵作为基础的损失函数和重叠度量作为加权正则函数的损失函数在训练过程中显示出更高的稳定性。

![损失函数_3](.\TyporaImg\损失函数_3.png)

在大背景中具有非常小的前景对象的情况下，DL效果好于原始的交叉熵。



#### **（论文）Transformation-consistent Self-ensembling Model for Semi-supervised Medical Image Segmentation**

对于有标签的输入，有一个普通监督损失（交叉熵）；对于所有数据，有一个正则化损失（均方差损失）。该网络是两者的加权组合。

![损失函数_1](.\TyporaImg\损失函数_1.png)



#### **（论文）Learning Active Contour Models for Medical Image Segmentation**

设计新的损失函数，将传统的主动轮廓能量最小化利用到卷积神经网络中。![损失函数_2](.\TyporaImg\损失函数_2.png)



#### **（论文）Reducing the Hausdorff Distance in Medical Image Segmentation with Convolutional Neural Networks**

Hausdorff Distance（HD）是一种评估医学图像分割结果的方式；文中提出了新的损失函数，目的是**直接降低**HD，而且不降低其他分割性能标准，如Dice Loss。