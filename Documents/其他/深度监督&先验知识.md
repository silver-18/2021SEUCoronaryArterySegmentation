> ![](TyporaImg\QQ图片20210416231755.jpg)

------



## 第一部分 深度监督

### 概述

- 所谓**深度监督(Deep Supervision)**，就是在深度神经网络的某些**中间隐藏层**加了一个**辅助的分类器**作为一种网络分支来对主干网络进行监督的技巧，用来解决深度神经网络**训练梯度消失**和**收敛速度过慢**等问题。

- 最早在2014年，有一篇主题为DSN(Deeply-Supervised Nets)[1]的论文提出。2015年的一篇Training Deeper Convolutional Networks with Deep Supervision[2]的论文尝试了在更深层结构的网络中使用深度监督技巧。

### 结构

- 通常而言，增加神经网络的深度可以一定程度上提高网络的表征能力，但随着深度加深，会逐渐出现**神经网络难以训练**的情况，其中就包括像**梯度消失**和**梯度爆炸**等现象。为了更好的训练深度网络，我们可以尝试给神经网络的某些层添加一些**辅助的分支分类器**来解决这个问题。这种辅助的分支分类器能够起到一种**判断隐藏层特征图质量好坏**的作用。

- 论文[2]作者根据一些经验法则和实验给出了结论。作者先是把深监督放在网络最后一层，然后跑10-50次迭代，绘制出**中间层的平均梯度值**。然后作者将监督分支添加在**平均梯度消失**(原文中平均梯度小于10e-7)的那一层。随迭代次数变化的各卷积层的平均梯度值如下图所示。在他们的8层网络模型中，第4个卷积层的梯度开始消失，因此将辅助监督分类器加在这一层之后。

![](TyporaImg\梯度消失.jpg)

- 带有深度监督的8层和13层网络结构，以及各个模块含义，如下图所示。

![](TyporaImg\8-layer.png)

![](TyporaImg\13-layer.png)

![](TyporaImg\meaning.png)

- 可以看到，图中在第四个卷积块之后添加了一个监督分类器作为分支。Conv4输出的特征图除了随着主网络进入Conv5之外，也作为输入进入了分支分类器。如图所示，该分支分类器包括一个卷积块、两个带有Dropout和ReLu的全连接块和一个纯全连接块。

### 损失函数

以$\mathcal{W}$和$\mathcal{W_s}$表示主干网络和深度监督分支的权重。

$$
\mathcal{W}=(W_1,\dots,W_{11}),\\\mathcal{W_s}=(W_{s5},\dots,W_{s8}).
$$
输出层softmax表示为：
$$
p_k=\frac{\exp(X_{11(k)})}{\begin{matrix}\sum_k \exp(X_{11(k)})\end{matrix}}
$$
主干网络的损失函数为：
$$
\mathcal{L}_0(\mathcal{W})=-\sum_{k=1}^K\space y_k\ln p_k
$$
深度监督分支的softmax输出为：
$$
p_{sk}=\frac{\exp(S_{8(k)})}{\begin{matrix}\sum_k \exp(S_{8(k)})\end{matrix}}
$$
深度监督分支的损失函数为：
$$
\mathcal{L}_s(\mathcal{W},\mathcal{W_s})=-\sum_{k=1}^K\space y_k\ln p_{sk}
$$
所以，联合损失函数可以表示为：
$$
\mathcal{L}(\mathcal{W},\mathcal{W_s})=\mathcal{L}_0(\mathcal{W})+\alpha_t\mathcal{L}_s(\mathcal{W},\mathcal{W_s})
$$
其中$\alpha_t$可以看作随训练轮数衰减的一个值：
$$
\alpha_t\leftarrow\alpha_t*(1-t/N)
$$

### Torch示例

下面以Torch为例实现一个带深度监督的卷积模块。先定义卷积块：

```python
import torch.nn as nn
# 定义卷积块
# 包含3x3卷积+BN+relu
def conv3x3_bn_relu(in_planes, out_planes, stride=1):
    "3x3 convolution + BN + relu"
    return nn.Sequential(
            nn.Conv2d(in_planes, out_planes, kernel_size=3,
                      stride=stride, padding=1, bias=False),
            BatchNorm2d(out_planes),
            nn.ReLU(inplace=True),
            )
```

带有深监督的卷积模块如下：

```python
class C1DeepSup(nn.Module):
    def __init__(self, num_class=150, fc_dim=2048, use_softmax=False):
        super(C1DeepSup, self).__init__()
        self.use_softmax = use_softmax
        self.cbr = conv3x3_bn_relu(fc_dim, fc_dim // 4, 1)
        self.cbr_deepsup = conv3x3_bn_relu(fc_dim // 2, fc_dim // 4, 1)
        # 最后一层卷积
        self.conv_last = nn.Conv2d(fc_dim // 4, num_class, 1, 1, 0)
        self.conv_last_deepsup = nn.Conv2d(fc_dim // 4, num_class, 1, 1, 0)
 
    # 前向计算流程
    def forward(self, conv_out, segSize=None):
        conv5 = conv_out[-1]
        x = self.cbr(conv5)
        x = self.conv_last(x)
        if self.use_softmax:  # is True during inference
            x = nn.functional.interpolate(
                x, size=segSize, mode='bilinear', align_corners=False)
            x = nn.functional.softmax(x, dim=1)
            return x
        # 深监督模块
        conv4 = conv_out[-2]
        _ = self.cbr_deepsup(conv4)
        _ = self.conv_last_deepsup(_)
        
        # 主干卷积网络softmax输出
        x = nn.functional.log_softmax(x, dim=1)
        # 深监督分支网络softmax输出
        _ = nn.functional.log_softmax(_, dim=1)
        return (x, _)
```

#### 参考文献

[1] Lee C Y ,  Xie S ,  Gallagher P , et al. Deeply-Supervised Nets[J]. Eprint Arxiv, 2014:562-570.

[2] Wang L ,  Lee C Y ,  Tu Z , et al. Training Deeper Convolutional Networks with Deep Supervision[J]. Computer Science, 2015.

------

## 第二部分 深度学习先验知识

### 深度学习的问题

- 在使用传统的深度学习网络对病灶进行分割时，如，FCNN, U-Net, Dense U-Net等，网络均只考虑了本身图像上的信息，让网络本身通过大量的图像与label的对应关系，进行深度学习模型的训练。这一系列过程中没有任何人工的干预以及人为的先验信息。当数据量十分巨大时，这种做法往往能够取得非常好的分割效果，但当数据量相对较小时，如很多医学影像数据往往只有几十张精准标注的图像，引入医生本身的解剖学信息往往能够取得更好的分割效果。但问题的难点在于**如何将医生的临床知识进行量化表示，并与深度学习的分割相结合。**

- Zheng et al. Anatomically Constrained Deep Learning for Automating Dental CBCT Segmentation and Lesion Detection[3] 在牙齿的CT图像上，在**Dense U-Net**基础上，考虑**引入了解剖学的知识**——例如，病灶部位附近不会有background，materials不会直接连接骨头。

### 优化方法

- 在深度学习分割网络中，我们的优化的目标函数通常为如下形式：

$$
\frac{1}{N}\sum_{(x,y)\in D_l}\mathcal{L}(\bold{y},p_\theta (\bold{y}\space|\space\bold{x}))
$$

- 其中$D_l$为训练集， $p_{\theta}$为深度学习模型， $\bold{x}$为原图， $\bold{y}$是原图对应的label，两者均为向量，向量的长度为图像像素点的个数。而文章在这里考虑了一个新的得分函数，$f(y)$，得分越高表示越符合解剖学的先验知识。为了更好的适用于一组图像，这里考虑了平均意义下的得分函数，也就是对其添加了期望，期望是关于$p_{\theta} $的条件分布下的。此时，目标优化问题变为了：

$$
\min_\theta\left\{\frac{1}{N}\sum_{(x,y)\in D_l}\mathcal{L}(\bold{y},p_\theta (\bold{y}\space|\space\bold{x}))-\alpha \frac{1}{N}\sum_{x\in D_l}E_{p_\theta(\bold{y}|\bold{x})}(f(\bold{y}))\right\}
$$

- 这里的$\alpha$为tuning parameter。但到这里会发现，上述的目标函数根本无法计算，原因是$p_{\theta}$的维度过高，为像素点个数，因此对应的期望就无法进行求解。文章在这里考虑使用了变分推断的方法，用一个$q$函数来近似$p_{\theta}$，根据标准的变分推断理论，只需使得两者之间的**KL散度**尽可能小。

> KL散度是两个概率分布P和Q差别的非对称性的度量，其通常用来度量使用基于Q的分布来编码服从P的分布的样本所需的额外的平均比特数。典型情况下，P表示数据的真实分布，Q表示数据的理论分布、估计的模型分布、或P的近似分布。
>
> 对于离散型随机变量，概率分布P和Q的KL散度定义为
> $$
> D_{KL}(P||Q)=\sum_i P(i)\space ln\frac{P(i)}{Q(i)}
> $$
> 对于连续型随机变量，概率分布P和Q的KL散度定义为（p和q分别表示分布P和Q的密度）
> $$
> D_{KL}(P||Q)=\int_{-\infty}^\infty p(x)\space ln\frac{p(x)}{q(x)}dx
> $$

- 为使$q$与$p_{\theta}$之间的KL散度尽可能小，只需使得在$p_{\theta}$上的期望变为$q$上的期望即可。当我们给定$\theta$时，此时的优化目标变为：

$$
\min_q \mbox{KL}(q(\bold{y}\space|\space\bold{x})||p_\theta(\bold{y}\space|\space\bold{x}))-\lambda E_{q(\bold{y}|\bold{x})}(f(\bold{y}))
$$

- 其中$\lambda$为tuning parameter。由于上式为凸的，对其进行求导，可以得到**最优$q$的显示表达式**：

$$
q^*(\bold{y}\space|\space\bold{x})=\frac{1}{C} p_\theta (\bold{y}\space|\space\bold{x}) \space \exp \lambda \left\{f(\bold{y})\right\}
$$

### 最终算法框架及效果

![](TyporaImg\Oral-anatomical knowledge.png)

![](TyporaImg\result.png)

- 第三列的为添加了先验知识的结果，可以发现效果更好。

#### 参考文献

[3] Zheng Z ,  Yan H ,  Setzer F C , et al. Anatomically Constrained Deep Learning for Automating Dental CBCT Segmentation and Lesion Detection[J]. IEEE Transactions on Automation Science and Engineering, 2020, PP(99):1-12.

------

#### 建议

- 搜索“树状结构”“管状结构”，而非“先验知识”
- 先验知识的不同嵌入方法，如图卷积

- 设计新的浅层神经网络，或直接加，想办法深度监督和先验知识结合

- 加入深度监督模块
- 搜索边缘算子的损失函数方法